{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "def"
    ]
   },
   "source": [
    "# TESS Atlas fit for TOI {{{TOINUMBER}}}\n",
    "\n",
    "**Version: {{{VERSIONNUMBER}}}**\n",
    "\n",
    "**Note: This notebook was automatically generated as part of the TESS Atlas project. More information can be found on GitHub:** [github.com/dfm/tess-atlas](https://github.com/dfm/tess-atlas)\n",
    "\n",
    "In this notebook, we do a quicklook fit for the parameters of the TESS Objects of Interest (TOI) in the system number {{{TOINUMBER}}}.\n",
    "To do this fit, we use the [exoplanet](https://exoplanet.dfm.io) library and you can find more information about that project at [exoplanet.dfm.io](https://exoplanet.dfm.io).\n",
    "\n",
    "From here, you can scroll down and take a look at the fit results, or you can:\n",
    "\n",
    "- [open the notebook in Google Colab to run the fit yourself](https://colab.research.google.com/github/dfm/tess-atlas/blob/gh-pages/notebooks/{{{VERSIONNUMBER}}}/toi-{{{TOINUMBER}}}.ipynb),\n",
    "- [view the notebook on GitHub](https://github.com/dfm/tess-atlas/blob/gh-pages/notebooks/{{{VERSIONNUMBER}}}/toi-{{{TOINUMBER}}}.ipynb), or\n",
    "- [download the notebook](https://github.com/dfm/tess-atlas/raw/gh-pages/notebooks/{{{VERSIONNUMBER}}}/toi-{{{TOINUMBER}}}.ipynb).\n",
    "\n",
    "\n",
    "\n",
    "## Caveats\n",
    "\n",
    "There are many caveats associated with this relatively simple \"quicklook\" type of analysis that should be kept in mind.\n",
    "Here are some of the main things that come to mind:\n",
    "\n",
    "1. The orbits that we fit are constrained to be *circular*. One major effect of this approximation is that the fit will significantly overestimate the confidence of the impact parameter constraint, so the results for impact parameter shouldn't be taken too seriously. \n",
    "\n",
    "2. Transit timing variations, correlated noise, and (probably) your favorite systematics are ignored. Sorry!\n",
    "\n",
    "3. This notebook was generated automatically without human intervention. Use at your own risk!\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Getting started](#Getting-started)\n",
    "2. [Data & de-trending](#Data-%26amp%3B-de-trending)\n",
    "3. [Removing stellar variability](#Removing-stellar-variability)\n",
    "4. [Transit model in PyMC3 & exoplanet](#Transit-model-in-PyMC3-%26amp%3B-exoplanet)\n",
    "5. [Sampling](#Sampling)\n",
    "6. [Posterior constraints](#Posterior-constraints)\n",
    "7. [Attribution](#Attribution)\n",
    "\n",
    "## Getting started\n",
    "\n",
    "To get going, we'll need to make out plots show up inline and install a few packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "exe"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "def"
    ]
   },
   "source": [
    "Then we'll set up the plotting styles and do all of the imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "def"
    ]
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import logging\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "from copy import deepcopy\n",
    "\n",
    "import arviz as az\n",
    "from celerite2.theano import terms, GaussianProcess\n",
    "import corner\n",
    "import exoplanet as xo\n",
    "import lightkurve as lk\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import pymc3_ext as pmx\n",
    "import theano.tensor as tt\n",
    "from IPython.display import display\n",
    "from astroquery.mast import Catalogs\n",
    "\n",
    "from tess_atlas.data import TICEntry\n",
    "from tess_atlas.plotting import plot_lightcurve_and_masks, plot_masked_lightcurve_flux_vs_time_since_transit, plot_lightcurve_with_inital_model\n",
    "\n",
    "get_ipython().magic('config InlineBackend.figure_format = \"retina\"')\n",
    "\n",
    "# TEMPORARY WORKAROUND\n",
    "try:\n",
    "    mp.set_start_method(\"fork\")\n",
    "except RuntimeError: # \"Multiprocessing context already set\"\n",
    "    pass\n",
    "    \n",
    "# Don't use the schmantzy progress bar\n",
    "os.environ[\"EXOPLANET_NO_AUTO_PBAR\"] = \"true\"\n",
    "\n",
    "# Warning\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Logging setup\n",
    "logger = logging.getLogger(\"theano.gof.compilelock\")\n",
    "logger.setLevel(logging.ERROR)\n",
    "logger = logging.getLogger(\"exoplanet\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# matplotlib settings\n",
    "plt.style.use(\"default\")\n",
    "plt.rcParams[\"savefig.dpi\"] = 100\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "plt.rcParams[\"font.size\"] = 16\n",
    "plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"Liberation Sans\"]\n",
    "plt.rcParams[\"font.cursive\"] = [\"Liberation Sans\"]\n",
    "plt.rcParams[\"mathtext.fontset\"] = \"custom\"\n",
    "plt.rcParams['image.cmap'] = 'inferno'\n",
    "\n",
    "\n",
    "# Constants\n",
    "TOI_DATASOURCE = (\n",
    "    \"https://exofop.ipac.caltech.edu/tess/download_toi.php?sort=toi&output=csv\"\n",
    ")\n",
    "\n",
    "MIN_NUM_DAYS = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "exe"
    ]
   },
   "outputs": [],
   "source": [
    "TOI_NUMBER = {{{TOINUMBER}}}\n",
    "__version__ = {{{VERSIONNUMBER}}}\n",
    "FILENAME = {{{FILENAME}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting stellar parameters\n",
    "\n",
    "Next, we define some code to grab the TOI list from [ExoFOP](https://exofop.ipac.caltech.edu/tess/) to get the information about the system.\n",
    "\n",
    "We wrap the information in three objects, a `TIC Entry`, a `Planet Candidate` and finally a `Lightcurve Data` object.\n",
    "\n",
    "- The `TIC Entry` object holds one or more `Planet Candidate`s (each candidate associated with one TOI id number) and a `Lightcurve Data` for associated with the candidates. Note that the `Lightcurve Data` object is initially the same fopr each candidate but may be masked according to the candidate transit's period.\n",
    "\n",
    "- The `Planet Candidate` holds informaiton on the TOI data collected by [SPOC](https://heasarc.gsfc.nasa.gov/docs/tess/pipeline.html) (eg transit period, etc)\n",
    "\n",
    "- The `Lightcurve Data` holds the lightcurve time and flux data for the planet candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "exe"
    ]
   },
   "outputs": [],
   "source": [
    "tic_entry = TICEntry.generate_tic_from_toi_number(toi=TOI_NUMBER)\n",
    "tic_entry.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets download and plot the TESS light curve data for the `Planet Candidate`s using [lightkurve](https://docs.lightkurve.org/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "exe"
    ]
   },
   "outputs": [],
   "source": [
    "tic_entry.load_lightcurve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "exe"
    ]
   },
   "outputs": [],
   "source": [
    "plot_lightcurve_and_masks(tic_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For efficiency purposes, let's extract just the data within 0.25 days of the transits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "exe"
    ]
   },
   "outputs": [],
   "source": [
    "# tic_entry.mask_lightcurve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "exe"
    ]
   },
   "outputs": [],
   "source": [
    "plot_masked_lightcurve_flux_vs_time_since_transit(tic_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks a little janky, but it's good enough for now.\n",
    "\n",
    "## The probabilistic model\n",
    "\n",
    "We use the probabilistic model as described in [Foreman-Mackey et al 2017] to determine the best parameters to fit the transits present in the lightcurve data.\n",
    "\n",
    "More explicitly, the stellar light curve $l(t; \\vec{\\theta})$ is modelled with a Gaussian Process (GP). A GP consists of a mean function $\\mu(t;\\vec{\\theta})$ and a kernel function $k_\\alpha(t,t';\\vec{\\theta})$, where $\\vec{\\theta}$ is the vector of parameters descibing the lightcurve and $t$ is the time during which the lightcurve is under observation\n",
    "\n",
    "The parameters describing the lightcurve are \n",
    "$\\vec{\\theta}$ = {  \n",
    "&emsp;$p_i$ (orbital periods for each planet),  \n",
    "&emsp;$d_i$ (transit durations for each planet),  \n",
    "&emsp;$t0_i$ (transit phase/epoch for each planet),  \n",
    "&emsp;$b_i$ (impact parameter for each planet),  \n",
    "&emsp;$r_i$ (planet radius in stellar radius for each planet),  \n",
    "&emsp;$f0$ (baseline relative flux of the light curve from star),  \n",
    "&emsp;$u1$ $u2$ (two parameters describing the limb-darkening profile of star)  \n",
    "}\n",
    "\n",
    "With this we can write \n",
    "$$l(t;\\vec{\\theta}) \\sim \\mathcal{GP} (\\mu(t;\\vec{\\theta}), k_\\alpha(t,t';\\vec{\\theta}))\\ .$$\n",
    "\n",
    "Here the mean and kernel functions are:\n",
    "* $\\mu(t;\\vec{\\theta})$: a limb-darkened transit light curve ([Kipping 2013])\n",
    "* $k_\\alpha(t,t';\\vec{\\theta}))$: a stochastically-driven, damped harmonic oscillator ([SHOTterm])\n",
    "\n",
    "\n",
    "Now that we have defined our transit model, we can implement it in python:\n",
    "\n",
    "[Foreman-Mackey et al 2017]: https://arxiv.org/pdf/1703.09710.pdf\n",
    "[Kipping 2013]: https://arxiv.org/abs/1308.0009\n",
    "[SHOTterm]: https://celerite2.readthedocs.io/en/latest/api/python/?highlight=SHOTerm#celerite2.terms.SHOTerm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "def"
    ]
   },
   "outputs": [],
   "source": [
    "def build_planet_transit_model(tic_entry):\n",
    "    n = tic_entry.planet_count\n",
    "    t0s = np.array([planet.t0 for planet in tic_entry.candidates])\n",
    "    depths = np.array([planet.depth for planet in tic_entry.candidates])\n",
    "    periods = np.array([planet.period for planet in tic_entry.candidates])\n",
    "    \n",
    "    t = tic_entry.lightcurve.time\n",
    "    y = tic_entry.lightcurve.flux \n",
    "    yerr = tic_entry.lightcurve.flux_err \n",
    "\n",
    "    with pm.Model() as my_planet_transit_model:\n",
    "        ## define planet 𝜃⃗ \n",
    "        t0 = pm.Normal(\"t0\", mu=t0s, sd=1.0, shape=n)\n",
    "        p = pm.Lognormal(\"p\", mu=np.log(periods), sd=1.0, shape=n)\n",
    "        d = pm.Lognormal(\"d\", mu=np.log(0.1), sigma=10.0, shape=n)\n",
    "        r = pm.Lognormal(\"r\", mu=0.5 * np.log(depths * 1e-3), sd=1.0, shape=n)\n",
    "        b = xo.distributions.ImpactParameter(\"b\", ror=r, shape=n)\n",
    "        planet_parms = [r, d, b]\n",
    "        \n",
    "        ## define stellar 𝜃⃗ \n",
    "        f0 = pm.Normal(\"f0\", mu=0.0, sd=10.0)\n",
    "        u = xo.distributions.QuadLimbDark(\"u\")\n",
    "        stellar_params = [f0, u]\n",
    "        \n",
    "        ## define 𝑘(𝑡,𝑡′;𝜃⃗ )\n",
    "        jitter = pm.InverseGamma(\"jitter\", **pmx.estimate_inverse_gamma_parameters(1.0, 5.0))\n",
    "        sigma = pm.InverseGamma(\"sigma\", **pmx.estimate_inverse_gamma_parameters(1.0, 5.0))\n",
    "        rho = pm.InverseGamma(\"rho\", **pmx.estimate_inverse_gamma_parameters(0.5, 10.0))\n",
    "        kernel = terms.SHOTerm(sigma=sigma, rho=rho, Q=0.3)\n",
    "        noise_params = [jitter, sigma, rho]\n",
    "\n",
    "        ## define 𝜇(𝑡;𝜃) (ie light)\n",
    "        orbit = xo.orbits.KeplerianOrbit(period=p, t0=t0, b=b)\n",
    "        lightcurves = xo.LimbDarkLightCurve(u).get_light_curve(orbit=orbit, r=r, t=t)\n",
    "        lightcurve = 1e3 * pm.math.sum(lightcurves, axis=-1) + f0\n",
    "        lightcurves = pm.Deterministic(\"lightcurves\", lightcurves)\n",
    "        rho_circ = pm.Deterministic(\"rho_circ\", orbit.rho_star)\n",
    "        \n",
    "        # Finally the GP observation model\n",
    "        residual = y - lightcurve\n",
    "        gp = GaussianProcess(kernel, t=t, diag=yerr ** 2 + jitter ** 2, mean=lightcurve)\n",
    "        gp.marginal(\"obs\", observed=y)\n",
    "\n",
    "        # cache params\n",
    "        my_params = dict(\n",
    "            planet_params=planet_parms,\n",
    "            noise_params=noise_params,\n",
    "            stellar_params=stellar_params,\n",
    "        )\n",
    "    return my_planet_transit_model, my_params, gp\n",
    "\n",
    "\n",
    "def test_model(model):\n",
    "    \"\"\"Test a point in the model and assure no nans\"\"\"\n",
    "    with model:\n",
    "        test_prob = model.check_test_point()\n",
    "        test_prob.name=\"log P(test-point)\"\n",
    "        assert not test_prob.isnull().values.any(), test_prob\n",
    "        test_pt = pd.Series(\n",
    "            {k:str(round(np.array(v).flatten()[0],2)) for k,v in model.test_point.items()},\n",
    "            name=\"Test Point\"\n",
    "        )\n",
    "        return pd.concat([test_pt, test_prob], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "exe"
    ]
   },
   "outputs": [],
   "source": [
    "planet_transit_model, params, gp = build_planet_transit_model(tic_entry)\n",
    "test_model(planet_transit_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test point acts as an example of a point in the parameter space.\n",
    "We can now optimize the model sampling parameters before initialising the sampler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "def"
    ]
   },
   "outputs": [],
   "source": [
    "def get_optimized_init_params(model, planet_params, noise_params, stellar_params):\n",
    "    \"\"\"Get params with maximimal log prob for sampling starting point\"\"\"\n",
    "    print(\"Optimizing sampling starting point\")\n",
    "    with model:\n",
    "        theta = model.test_point\n",
    "        kwargs = dict(start=theta, verbose=False, progress=False)\n",
    "        theta = pmx.optimize(**kwargs, vars=[noise_params[0]])\n",
    "        theta = pmx.optimize(**kwargs, vars=planet_params)\n",
    "        theta = pmx.optimize(**kwargs, vars=noise_params)\n",
    "        theta = pmx.optimize(**kwargs, vars=stellar_params)\n",
    "    print(\"Optimization complete!\")\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "exe"
    ]
   },
   "outputs": [],
   "source": [
    "init_params = get_optimized_init_params(planet_transit_model, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot our initial model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "exe"
    ]
   },
   "outputs": [],
   "source": [
    "plot_lightcurve_with_inital_model(tic_entry, init_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "exe"
    ]
   },
   "outputs": [],
   "source": [
    "plot_masked_lightcurve_flux_vs_time_since_transit(\n",
    "    tic_entry=tic_entry,\n",
    "    model_lightcurves=[init_params[\"lightcurves\"][:,i]*1e3 for i in range(tic_entry.planet_count)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks better!\n",
    "\n",
    "Now on to sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "def"
    ]
   },
   "outputs": [],
   "source": [
    "TUNE = 2000\n",
    "DRAWS = 2000\n",
    "\n",
    "def start_model_sampling(model):\n",
    "    np.random.seed(TOI_NUMBER)\n",
    "\n",
    "    with model:\n",
    "        trace = pmx.sample(\n",
    "            tune=TUNE,\n",
    "            draws=DRAWS,\n",
    "            start=init_params,\n",
    "            chains=2,\n",
    "            cores=2,\n",
    "        )\n",
    "        return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "exe"
    ]
   },
   "outputs": [],
   "source": [
    "trace = start_model_sampling(planet_transit_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can take a look at the summary statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "exe"
    ]
   },
   "outputs": [],
   "source": [
    "az.from_pymc3(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot the posterior covariances compared to the values from [Pepper et al. (2019)](https://arxiv.org/abs/1911.05150):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "def"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_posteriors(trace):\n",
    "    samples = pm.trace_to_dataframe(trace, varnames=[\"p\", \"r\", \"b\"])\n",
    "    corner.corner(samples);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "exe"
    ]
   },
   "outputs": [],
   "source": [
    "plot_posteriors(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we save the posteriors and sampling metadata for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "def"
    ]
   },
   "outputs": [],
   "source": [
    "def validate_trace_filename(filename):\n",
    "    suffix = Path(filename).suffix\n",
    "    if suffix != \".netcdf\":\n",
    "        raise ValueError(f\"{suffix} is an invalid extension.\")\n",
    "\n",
    "def save_trace(trace, filename):\n",
    "    \"\"\"Save pymc3 trace as a netcdf file\"\"\"\n",
    "    validate_trace_filename(filename)\n",
    "    az_trace = az.from_pymc3(trace)\n",
    "    az_trace.to_netcdf(filename)\n",
    "\n",
    "def load_trace(filename):\n",
    "    \"\"\"Load pymc3 trace from netcdf file and return an arviz InferenceData object\"\"\"\n",
    "    validate_trace_filename(filename)\n",
    "    return az.from_netcdf(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "exe"
    ]
   },
   "outputs": [],
   "source": [
    "trace_filename = os.path.basename(FILENAME.replace(\".ipynb\", \".netcdf\"))\n",
    "save_trace(trace, trace_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: eccentricity\n",
    "\n",
    "As discussed above, we fit this model assuming a circular orbit which speeds things up for a few reasons.\n",
    "First, setting eccentricity to zero means that the orbital dynamics are much simpler and more computationally efficient, since we don't need to solve Kepler's equation numerically.\n",
    "But this isn't actually the main effect!\n",
    "Instead the bigger issues come from the fact that the degeneracies between eccentricity, arrgument of periasteron, impact parameter, and planet radius are hard for the sampler to handle, causing the sampler's performance to plummet.\n",
    "In this case, by fitting with a circular orbit where duration is one of the parameters, everything is well behaved and the sampler runs faster.\n",
    "\n",
    "But, in this case, the planet *is* actually on an eccentric orbit, so that assumption isn't justified.\n",
    "It has been recognized by various researchers over the years (I first learned about this from [Bekki Dawson](https://arxiv.org/abs/1203.5537)) that, to first order, the eccentricity mainly just changes the transit duration.\n",
    "The key realization is that this can be thought of as a change in the impled density of the star.\n",
    "Therefore, if you fit the transit using stellar density (or duration, in this case) as one of the parameters (*note: you must have a* different *stellar density parameter for each planet if there are more than one*), you can use an independent measurement of the stellar density to infer the eccentricity of the orbit after the fact.\n",
    "All the details are described in [Dawson & Johnson (2012)](https://arxiv.org/abs/1203.5537), but here's how you can do this here using the stellar density listed in the TESS input catalog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "def"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_reweighted_ecentricity_samples(tic_number, trace):\n",
    "    star = Catalogs.query_object(f\"TIC {tic_number}\", catalog=\"TIC\", radius=0.001)\n",
    "    tic_rho_star = float(star[\"rho\"]), float(star[\"e_rho\"])\n",
    "    print(\"rho_star = {0} ± {1}\".format(*tic_rho_star))\n",
    "\n",
    "    # Extract the implied density from the fit\n",
    "    rho_circ = np.repeat(trace[\"rho_circ\"], 100)\n",
    "\n",
    "    # Sample eccentricity and omega from their priors (the math might\n",
    "    # be a little more subtle for more informative priors, but I leave\n",
    "    # that as an exercise for the reader...)\n",
    "    ecc = np.random.uniform(0, 1, len(rho_circ))\n",
    "    omega = np.random.uniform(-np.pi, np.pi, len(rho_circ))\n",
    "\n",
    "    # Compute the \"g\" parameter from Dawson & Johnson and what true\n",
    "    # density that implies\n",
    "    g = (1 + ecc * np.sin(omega)) / np.sqrt(1 - ecc ** 2)\n",
    "    rho = rho_circ / g ** 3\n",
    "\n",
    "    # Re-weight these samples to get weighted posterior samples\n",
    "    log_weights = -0.5 * ((rho - tic_rho_star[0]) / tic_rho_star[1]) ** 2\n",
    "    weights = np.exp(log_weights - np.max(log_weights))\n",
    "\n",
    "    # Estimate the expected posterior quantiles\n",
    "    q = corner.quantile(ecc, [0.16, 0.5, 0.84], weights=weights)\n",
    "    print(\"eccentricity = {0:.2f} +{1[1]:.2f} -{1[0]:.2f}\".format(q[1], np.diff(q)))\n",
    "\n",
    "    corner.corner(\n",
    "        np.vstack((ecc, omega)).T,\n",
    "        weights=weights,\n",
    "        plot_datapoints=False,\n",
    "        labels=[\"eccentricity\", \"omega\"],\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "exe"
    ]
   },
   "outputs": [],
   "source": [
    "plot_reweighted_ecentricity_samples(tic_entry.tic_number, trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this eccentricity estimate is consistent (albeit with large uncertainties) with the value that [Pepper et al. (2019)](https://arxiv.org/abs/1911.05150) measure using radial velocities and it is definitely clear that this planet is not on a circular orbit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citations\n",
    "\n",
    "As described in the :ref:`citation` tutorial, we can use :func:`exoplanet.citations.get_citations_for_model` to construct an acknowledgement and BibTeX listing that includes the relevant citations for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "exe"
    ]
   },
   "outputs": [],
   "source": [
    "with planet_transit_model:\n",
    "    txt, bib = xo.citations.get_citations_for_model()\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "exe"
    ]
   },
   "outputs": [],
   "source": [
    "print(\"\\n\".join(bib.splitlines()[:10]) + \"\\n...\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": false,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
